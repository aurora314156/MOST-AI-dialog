{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import time\n",
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精確模式 ：將句子最精確地切開，叫適合文本分析, cut_all=False\n",
    "# 全模式：把句子中所有的可以成詞的詞語都掃描出來, 速度快, cut_all=True\n",
    "# 搜索引擎模式：在精確模式的基礎上對長詞再次切分，提高召回率，適合用於搜尋引擎分詞, jieba.cut_for_search(Content)            \n",
    "# call jieba api\n",
    "def jiebaCut(s):\n",
    "    words = jieba.cut(s, cut_all=False)\n",
    "    result = removeStopWords(words)\n",
    "    return result\n",
    "\n",
    "# remove stopwords\n",
    "def removeStopWords(words):\n",
    "    result = []\n",
    "    for w in words:\n",
    "        if w not in stopWordsSet:\n",
    "            result.append(w)\n",
    "    return result\n",
    "\n",
    "# define all state \n",
    "def state(s,flag):\n",
    "    nextline = 1\n",
    "    if s is None or s == \"\":\n",
    "        return flag, nextline\n",
    "    # state: 1, s[0] = C\n",
    "    if s[0] == 'C':\n",
    "        flag, nextline = 1, 0\n",
    "    # state: 2, s[0] = Q\n",
    "    elif s[0] == 'Q':\n",
    "        flag, nextline = 2, 0\n",
    "    # state: 3, s[0] = A\n",
    "    elif s[0] == 'A':\n",
    "        flag, nextline = 3, 0\n",
    "    # state: 4, do jieba cut\n",
    "    return flag, nextline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sTime = time.time()\n",
    "    print(\"Start process CQA dataset\")\n",
    "    cNum = 0\n",
    "    with open('CQA.txt', 'r') as file:\n",
    "        flag, end = 0, 0\n",
    "        cList, qList, aList = [],[],[]\n",
    "        tempC = []\n",
    "        ans = \"\"\n",
    "        for i in file.readlines():\n",
    "            s = i.strip()\n",
    "            flag, nextline = state(s,flag)\n",
    "            # one corpus process done!\n",
    "            if end == 4:\n",
    "                cNum +=1\n",
    "                ans = s\n",
    "                word2VecSum(cList, qList, aList, cNum)\n",
    "                print(\"Corpus: %d\" % cNum)\n",
    "                #print(\"corpus:\\n\",cList,'\\nquestion:\\n',qList,'\\nanswer:\\n',aList,'\\ncorrect ans:\\n',ans,'\\n')\n",
    "                cList, qList, aList = [],[],[]\n",
    "                flag, end = 0, 0\n",
    "                ans = \"\"\n",
    "                continue\n",
    "            # still on state\n",
    "            if nextline != 1:\n",
    "                continue\n",
    "            # on state 1, process Corpus\n",
    "            elif flag == 1:\n",
    "                cutRes = jiebaCut(s)\n",
    "                for c in cutRes:\n",
    "                    tempC.append(c)\n",
    "                if nextline == 1:\n",
    "                    if tempC:\n",
    "                        cList.append(tempC)\n",
    "                        tempC = []\n",
    "            # on state 2, process Question\n",
    "            elif flag == 2:\n",
    "                cutRes = jiebaCut(s)\n",
    "                for c in cutRes:\n",
    "                    qList.append(c)\n",
    "            # on state 3, process Answer\n",
    "            elif flag == 3:\n",
    "                end += 1\n",
    "                # example: （B） 吃飯比讀書更為重要 \n",
    "                tempS = \"\"\n",
    "                skip = ['A','B','C','D','（',')']\n",
    "                check = 0\n",
    "                for j in s:\n",
    "                    if check == 3:\n",
    "                        tempS += j\n",
    "                    else:\n",
    "                        check += 1\n",
    "                tempS = tempS.strip()\n",
    "                cutRes = jiebaCut(tempS)\n",
    "                tempL = []\n",
    "                for c in cutRes:\n",
    "                    tempL.append(c)\n",
    "                aList.append(tempL)\n",
    "\n",
    "        print(\"\\nTotal corpus numbers: %d\" % cNum)\n",
    "        print(\"Processing all CQA dataset corpus took %.2fs\" % (time.time()- sTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word2VecSum(cList, qList, aList, cNum):\n",
    "\n",
    "    sTime = time.time()\n",
    "    print(\"Start process words vector sum, corpus : %d\" % (cNum))\n",
    "    nc = np.zeros((len(cList),250),dtype=float)\n",
    "    nq = np.zeros(250,dtype=float)\n",
    "    na = np.zeros((len(aList),250),dtype=float)\n",
    "    count, ind = 0 , 0\n",
    "    # take all element from corpus List\n",
    "    for c in cList:\n",
    "        for w in c:\n",
    "            # take word vector from word2vec model\n",
    "            print(w)\n",
    "            try:\n",
    "                m = model[w]\n",
    "            except KeyError as e:\n",
    "                print('this word is not in model.')\n",
    "                continue\n",
    "            # calculate word vector sum from corpus list\n",
    "            for n in range(250):\n",
    "                nc[ind][n] += m[n]\n",
    "            count +=1\n",
    "        ind +=1\n",
    "    # take all element from question List\n",
    "    for w in qList:\n",
    "        try:\n",
    "            m = model[w]\n",
    "        except KeyError as e:\n",
    "            print('this word is not in model.')\n",
    "            continue\n",
    "        # calculate word vector sum from question list\n",
    "        for n in range(250):\n",
    "            nq[n] += m[n]\n",
    "        count +=1\n",
    "        \n",
    "    ind = 0\n",
    "     # take all element from answer List\n",
    "    for a in aList:\n",
    "        for w in a:\n",
    "            try:\n",
    "                m = model[w]\n",
    "            except KeyError as e:\n",
    "                print('this word is not in model.')\n",
    "                continue\n",
    "             # calculate word vector sum from answer list\n",
    "            for n in range(250):\n",
    "                na[ind][n] += m[n]\n",
    "            count +=1\n",
    "        ind +=1\n",
    "        \n",
    "    print(\"This corpus has total %d split words.\" % (count))\n",
    "    print(\"Process all corpus content took %.2fs.\\n\" % (time.time()- sTime))\n",
    "    # go to final step, calculate similarity\n",
    "    #similarity(nc, nq, na, cNum)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(nc, nq, na, cNum):\n",
    "    sTime = time.time()\n",
    "    print(\"Start process vector similarity, corpus : %d\" % (cNum))\n",
    "    print(nc)\n",
    "    print(nq)\n",
    "    for q in nq:\n",
    "        for c in nc:\n",
    "            highSim = 0\n",
    "            #cosSim = cosine_similarity(c,q)\n",
    "            cosSim =  1 - spatial.distance.cosine(c, q)\n",
    "            if cosSim > highSim:\n",
    "                highSim = cosSim\n",
    "                highC = c\n",
    "        print(highSim)\n",
    "    \n",
    "    print(\"Process all similarity calculation took %.2fs.\\n\" % (time.time()- sTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading initial setting!\n"
     ]
    }
   ],
   "source": [
    "# ====== initial setting ======\n",
    "\n",
    "print(\"Start loading initial setting!\")\n",
    "# jieba setting\n",
    "relativePath = os.getcwd()\n",
    "jieba.set_dictionary(relativePath + '/jieba_setting/dict.txt.big')\n",
    "# add user dictionary to improve jieba cut precision\n",
    "# jieba.load_userdict(relativePath + '/jieba_setting/yourfile.txt')\n",
    "\n",
    "# stopwords setting\n",
    "stopWordsSet = set()\n",
    "with open(relativePath + '/jieba_setting/stopwords.txt', 'r') as stop:\n",
    "    for i in stop:\n",
    "        stopWordsSet.add(i.strip('\\n'))\n",
    "\n",
    "# load word2vec model\n",
    "sTime = time.time()\n",
    "model = models.Word2Vec.load(relativePath + '/wiki/python/word2vec.model')\n",
    "print(\"Load word2vec model success! took %.2fs\" % (time.time()-sTime))\n",
    "\n",
    "# ====== initial setting ======\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
